{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Debug DeepSpeed",
            "type": "debugpy",
            "request": "launch",
            "program": "${env:DEEPSPEED}",
            "justMyCode": false,
            "console": "integratedTerminal",
            "args": [
                "--include",
                "localhost:0,1",
                "--master_port",
                "44000",
                "${env:VLLM_REPO}/internvl/train/internvl_chat_finetune.py",
                "${env:VLLM_REPO}/config/InternVL-8B-Debug-Pretrain.json"
            ],
            "env": {
                "PYTHONPATH": "${env:VLLM_REPO}",
                "WANDB_MODE": "offline"
            }
        },
        {
            "name": "Debug InternVL2-8B",
            "type": "debugpy",
            "request": "launch",
            "cwd": "${env:VLLM_REPO}",
            "program": "${env:DEEPSPEED}",
            "justMyCode": false,
            "console": "integratedTerminal",
            "args": [
                "--include",
                "localhost:0,1",
                "--master_port",
                "44000",
                "${env:VLLM_REPO}/internvl/train/internvl_chat_finetune.py",
                "${env:VLLM_REPO}/config/InternVL-8B-Low-Memory.json"
            ],
            "env": {
                "PYTHONPATH": "${env:VLLM_REPO}",
                "WANDB_MODE": "offline"
            }
        },
        {
            "name": "Debug Neg Mining",
            "type": "debugpy",
            "request": "launch",
            "program": "${env:VLLM_REPO}/visualization/neg_mine.py",
            "justMyCode": false,
            "console": "integratedTerminal",
            "args": [
                "${env:HOME}/output/embed/internvl_embedding_model",
                "5"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "PYTHONPATH": "${env:VLLM_REPO}",
                "WANDB_MODE": "offline"
            }
        },
        {
            "name": "Debug Visualization",
            "type": "debugpy",
            "request": "launch",
            "program": "${env:VLLM_REPO}/visualization/visualize_topk.py",
            "justMyCode": false,
            "console": "integratedTerminal",
            "args": [
                "/home/b3schnei/output/embed/internvl_embedding_model",
                "0",
                "10"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "1",
                "PYTHONPATH": "${env:VLLM_REPO}",
                "WANDB_MODE": "offline"
            }
        },
        {
            "name": "Debug Embed",
            "type": "debugpy",
            "request": "launch",
            "program": "${env:DEEPSPEED}",
            "justMyCode": false,
            "console": "integratedTerminal",
            "args": [
                "--include",
                "localhost:7",
                "--master_port",
                "44000",
                "${env:VLLM_REPO}/visualization/embed.py",
                "${env:VLLM_REPO}/config/embed/InternVL-1B-Optimized-Temperature.json",
                "10"
            ],
            "env": {
                "PYTHONPATH": "${env:VLLM_REPO}",
                "WANDB_MODE": "offline"
            }
        },
        {
            "name": "Debug Negative idx",
            "type": "debugpy",
            "request": "launch",
            "program": "${env:VLLM_REPO}/pretrain/create_negative_index.py",
            "justMyCode": false,
            "console": "integratedTerminal",
            "args": [
                "${env:VLLM_REPO}/config/InternVL-8B-Pretrain.json",
            ],
            "env": {
                "PYTHONPATH": "${env:VLLM_REPO}",
                "WANDB_MODE": "offline"
            }
        },
        {
            "name": "Debug vLLM",
            "type": "debugpy",
            "request": "launch",
            "program": "${env:VLLM_REPO}/finetune/generate_finetuning_data.py",
            "justMyCode": false,
            "console": "integratedTerminal",
            "args": [],
            "env": {
                "PYTHONPATH": "${env:VLLM_REPO}",
                "WANDB_MODE": "offline"
            }
        },
        {
            "name": "Debug Embed_",
            "type": "debugpy",
            "request": "launch",
            "program": "${env:VLLM_REPO}/visualization/embed_.py",
            "justMyCode": false,
            "console": "integratedTerminal",
            "args": [
                "${env:VLLM_REPO}/config/embed/InternVL-8B-Pretrain.json",
                "10"
            ],
            "env": {
                "PYTHONPATH": "${env:VLLM_REPO}",
                "WANDB_MODE": "offline",
                "CUDA_VISIBLE_DEVICES": "5"
            }
        },
        {
            "name": "Debug LastToken",
            "type": "debugpy",
            "request": "launch",
            "program": "${env:DEEPSPEED}",
            "justMyCode": false,
            "console": "integratedTerminal",
            "args": [
                "--include",
                "localhost:0,1",
                "--master_port",
                "44000",
                "${env:VLLM_REPO}/internvl/train/internvl_chat_finetune.py",
                "${env:VLLM_REPO}/config/lora_last_token.json"
            ],
            "env": {
                "PYTHONPATH": "${env:VLLM_REPO}",
                "WANDB_MODE": "offline"
            }
        },
        {
            "name": "Debug DeepSpeed - MULTIPLE GPU",
            "type": "debugpy",
            "request": "launch",
            "program": "${env:DEEPSPEED}",
            "justMyCode": false,
            "console": "integratedTerminal",
            "args": [
                "--include",
                "localhost:0,1",
                "--master_port",
                "44000",
                "${env:VLLM_REPO}/internvl/train/internvl_chat_finetune.py",
                "${env:VLLM_REPO}/config/debug.json"
            ],
            "env": {
                "PYTHONPATH": "${env:VLLM_REPO}",
                "WANDB_MODE": "offline"
            }
        }
    ]
}